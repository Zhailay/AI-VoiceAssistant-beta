// Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð°
let state = 'idle'; // idle, listening, processing, speaking

// Ð­Ð»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ DOM
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const circleContainer = document.getElementById('circleContainer');
const stateLabel = document.getElementById('stateLabel');
const transcriptBox = document.getElementById('transcriptBox');
const transcriptText = document.getElementById('transcript');
const responseBox = document.getElementById('responseBox');
const responseText = document.getElementById('response');

// Speech Recognition
let recognition = null;
let audioContext = null;
let analyser = null;
let audioLevel = 0;

// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Speech Recognition
function initSpeechRecognition() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

  if (!SpeechRecognition) {
    alert('Speech Recognition Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ð²Ð°ÑˆÐ¸Ð¼ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð¾Ð¼. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Chrome, Edge Ð¸Ð»Ð¸ Safari.');
    return;
  }

  recognition = new SpeechRecognition();
  recognition.continuous = false;
  recognition.interimResults = true;
  recognition.lang = 'ru-RU'; // Ð ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº
  recognition.maxAlternatives = 1;

  recognition.onstart = () => {
    console.log('âœ… Speech recognition STARTED');
    setState('listening');
  };

  recognition.onspeechstart = () => {
    console.log('ðŸŽ¤ Ð ÐµÑ‡ÑŒ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð°!');
  };

  recognition.onspeechend = () => {
    console.log('ðŸ”‡ Ð ÐµÑ‡ÑŒ Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð°ÑÑŒ');
  };

  recognition.onresult = async (event) => {
    console.log('ðŸ“ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚!');

    const last = event.results.length - 1;
    const result = event.results[last];

    console.log('Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹?', result.isFinal);
    console.log('Ð¢ÐµÐºÑÑ‚:', result[0].transcript);

    // ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
    if (result.isFinal) {
      const text = result[0].transcript;
      console.log('âœ… Ð¤Ð˜ÐÐÐ›Ð¬ÐÐ«Ð™ Ð¢Ð•ÐšÐ¡Ð¢:', text);

      // ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
      transcriptText.textContent = text;
      transcriptBox.style.display = 'block';

      setState('processing');

      // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð° LLM
      try {
        const response = await fetch('/api/llm', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ text })
        });

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}`);
        }

        const data = await response.json();
        console.log('âœ… ÐžÑ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½:', data.response.substring(0, 50) + '...');

        // ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚
        responseText.textContent = data.response;
        responseBox.style.display = 'block';

        // ÐžÐ·Ð²ÑƒÑ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚
        setState('speaking');
        speakText(data.response);
      } catch (error) {
        console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ°:', error);
        alert('ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ, Ñ‡Ñ‚Ð¾ Ollama Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½.');
        setState('idle');
      }
    } else {
      // ÐŸÑ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
      console.log('â³ ÐŸÑ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ð¹:', result[0].transcript);
    }
  };

  recognition.onerror = (event) => {
    console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ:', event.error);

    if (event.error === 'no-speech') {
      alert('Ð ÐµÑ‡ÑŒ Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ Ð³Ñ€Ð¾Ð¼Ñ‡Ðµ.');
    } else if (event.error === 'not-allowed') {
      alert('Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ðº Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ñƒ Ð·Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½.');
    } else if (event.error === 'network') {
      alert('ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ‚Ð¸. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚.');
    } else {
      alert('ÐžÑˆÐ¸Ð±ÐºÐ°: ' + event.error);
    }

    setState('idle');
  };

  recognition.onend = () => {
    console.log('ðŸ›‘ Recognition ended');
    setTimeout(() => {
      if (state === 'listening') {
        console.warn('âš ï¸ ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚');
        setState('idle');
      }
    }, 100);
  };

  console.log('âœ… Speech Recognition Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½');
}

// ÐÐ°Ñ‡Ð°Ñ‚ÑŒ ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ
async function startListening() {
  if (!recognition) {
    alert('Speech Recognition Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½');
    return;
  }

  try {
    console.log('ðŸŽ™ï¸ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ...');

    // ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ AudioContext Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);

      // ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°ÑƒÐ´Ð¸Ð¾ ÑƒÑ€Ð¾Ð²Ð½Ñ
      updateAudioLevel();
    } catch (err) {
      console.warn('âš ï¸ AudioContext Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½:', err);
    }

    // Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
    recognition.start();
    console.log('âœ… Recognition Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½!');
  } catch (error) {
    console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿ÑƒÑÐºÐ°:', error);
    if (error.name === 'InvalidStateError') {
      alert('Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ ÑƒÐ¶Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾');
    } else {
      alert('ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ');
    }
  }
}

// ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑƒÑ€Ð¾Ð²Ð½Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð»Ñ Ð°Ð½Ð¸Ð¼Ð°Ñ†Ð¸Ð¸
function updateAudioLevel() {
  if (analyser && state === 'listening') {
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteFrequencyData(dataArray);
    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
    audioLevel = average / 255;
    requestAnimationFrame(updateAudioLevel);
  }
}

// Text-to-Speech
// function speakText(text) {
//   if (!('speechSynthesis' in window)) {
//     console.error('Speech Synthesis Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ');
//     setState('idle');
//     return;
//   }

//   const utterance = new SpeechSynthesisUtterance(text);
//   utterance.lang = 'ru-RU';

//   utterance.onstart = () => {
//     setState('speaking');
//   };

//   utterance.onend = () => {
//     setState('idle');
//   };

//   utterance.onerror = () => {
//     setState('idle');
//   };

//   window.speechSynthesis.speak(utterance);
// }


async function speakText(text) {
  try {
    console.log('ðŸ”Š ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð½Ð° Ð¾Ð·Ð²ÑƒÑ‡ÐºÑƒ:', text.substring(0, 50) + '...');

    const response = await fetch('/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: text })
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }

    const data = await response.json();
    console.log('âœ… ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ð°ÑƒÐ´Ð¸Ð¾ Ñ„Ð°Ð¹Ð»:', data.file);

    const audio = new Audio(`/audio/${data.file}`);

    setState('speaking');

    audio.onended = () => {
      console.log('âœ… Ð’Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾');
      setState('idle');
    };

    audio.onerror = (err) => {
      console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾:', err);
      setState('idle');
    };

    await audio.play();

  } catch (err) {
    console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° TTS:', err);
    alert('ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÑ‡Ð¸. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ, Ñ‡Ñ‚Ð¾ Python API Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð½Ð° Ð¿Ð¾Ñ€Ñ‚Ñƒ 8000.');
    setState('idle');
  }
}


// Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
function setState(newState) {
  state = newState;

  const labels = {
    idle: 'Ð“Ð¾Ñ‚Ð¾Ð²',
    listening: 'Ð¡Ð»ÑƒÑˆÐ°ÑŽ...',
    processing: 'ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ...',
    speaking: 'Ð“Ð¾Ð²Ð¾Ñ€ÑŽ...'
  };

  stateLabel.textContent = labels[newState] || '';
  console.log('ðŸ”„ Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ:', newState);
}

// ÐÐ½Ð¸Ð¼Ð°Ñ†Ð¸Ñ ÐºÑ€ÑƒÐ³Ð°
function animate() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  const centerX = canvas.width / 2;
  const centerY = canvas.height / 2;
  const baseRadius = 100;

  let scale = 1;

  // ÐÐ½Ð¸Ð¼Ð°Ñ†Ð¸Ñ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
  switch (state) {
    case 'idle':
      scale = 1 + Math.sin(Date.now() * 0.002) * 0.1;
      break;
    case 'listening':
      scale = 1 + audioLevel * 0.5 + Math.sin(Date.now() * 0.01) * 0.2;
      break;
    case 'processing':
      scale = 1 + Math.sin(Date.now() * 0.001) * 0.15;
      break;
    case 'speaking':
      scale = 1 + Math.sin(Date.now() * 0.005) * 0.1;
      break;
  }

  const radius = baseRadius * scale;

  // Ð“Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚
  const gradient = ctx.createRadialGradient(centerX, centerY, 0, centerX, centerY, radius);

  // Ð¦Ð²ÐµÑ‚Ð° Ð¿Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÑÐ¼
  switch (state) {
    case 'idle':
      gradient.addColorStop(0, 'rgba(100, 100, 255, 0.8)');
      gradient.addColorStop(1, 'rgba(100, 100, 255, 0.2)');
      break;
    case 'listening':
      gradient.addColorStop(0, 'rgba(255, 100, 100, 0.8)');
      gradient.addColorStop(1, 'rgba(255, 100, 100, 0.2)');
      break;
    case 'processing':
      gradient.addColorStop(0, 'rgba(255, 255, 100, 0.8)');
      gradient.addColorStop(1, 'rgba(255, 255, 100, 0.2)');
      break;
    case 'speaking':
      gradient.addColorStop(0, 'rgba(100, 255, 100, 0.8)');
      gradient.addColorStop(1, 'rgba(100, 255, 100, 0.2)');
      break;
  }

  // Ð Ð¸ÑÑƒÐµÐ¼ ÐºÑ€ÑƒÐ³
  ctx.beginPath();
  ctx.arc(centerX, centerY, radius, 0, Math.PI * 2);
  ctx.fillStyle = gradient;
  ctx.fill();

  // ÐžÐ±Ð²Ð¾Ð´ÐºÐ°
  ctx.beginPath();
  ctx.arc(centerX, centerY, radius, 0, Math.PI * 2);
  ctx.strokeStyle = gradient;
  ctx.lineWidth = 3;
  ctx.stroke();

  requestAnimationFrame(animate);
}

// ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ»Ð¸ÐºÐ°
circleContainer.addEventListener('click', () => {
  if (state === 'idle') {
    startListening();
  }
});

// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
window.addEventListener('DOMContentLoaded', () => {
  console.log('ðŸš€ ÐŸÑ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾');
  initSpeechRecognition();
  animate();
});
